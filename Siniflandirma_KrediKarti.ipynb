{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KÜTÜPHANELER\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow.keras.models as Models\n",
    "import tensorflow.keras.layers as Layers\n",
    "import tensorflow.keras.optimizers as Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veriyi Yükleme\n",
    "\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "#Veri Kaynağı: https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Eksik Veri Kontrolü\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Hedef Değişkendeki Sınıfların Görselleştirilmesi\n",
    "\n",
    "sns.countplot(df.Class);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class sütununda çok büyük bir dengesizlik var. Bu çalışmada amaç, sahte alışverişleri tespit etmek. Hedef sınıftaki bu denli çarpıklık kurduğumuz modelleri yanıltacaktır. Belki yine doğruluk oranları yüksek olacaktır ancak sahte alışverişi tespit etmekte iyi olmayacaktır. Çünkü verinin geneli sahte olmayan alışverişdir ve model bunu öğrenir. Aşırı ezberlermeye (Overfitting) yol açabilir bu denli dengesizlik. Makine öğrenmesi süreçlerinde amaç genelleme yapabilmeyi sağlamaktır. Bu sebeplerden ötürü Class sütunu değeri 0'a eşit olan verilerden Class sütunu değeri 1'e eşit olanını kadarını rastgele seçip modeldeki hedef değişkendeki çarpıklığı önlüyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_test_split(df[df.Class == 0], test_size = 492, random_state = 4)\n",
    "\n",
    "df0 = pd.DataFrame(X[1])\n",
    "df1 = df[df.Class == 1]\n",
    "\n",
    "normal_df = pd.concat([df0, df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53794</th>\n",
       "      <td>46149.0</td>\n",
       "      <td>-1.346509</td>\n",
       "      <td>2.132431</td>\n",
       "      <td>-1.854355</td>\n",
       "      <td>2.116998</td>\n",
       "      <td>-1.070378</td>\n",
       "      <td>-1.092671</td>\n",
       "      <td>-2.230986</td>\n",
       "      <td>1.036425</td>\n",
       "      <td>-1.895516</td>\n",
       "      <td>-3.364011</td>\n",
       "      <td>2.887048</td>\n",
       "      <td>-3.784460</td>\n",
       "      <td>-1.288904</td>\n",
       "      <td>-3.985626</td>\n",
       "      <td>0.531838</td>\n",
       "      <td>-2.603703</td>\n",
       "      <td>-5.157596</td>\n",
       "      <td>-0.696010</td>\n",
       "      <td>1.285961</td>\n",
       "      <td>0.221919</td>\n",
       "      <td>0.609508</td>\n",
       "      <td>0.202874</td>\n",
       "      <td>-0.060791</td>\n",
       "      <td>-0.186733</td>\n",
       "      <td>-0.017401</td>\n",
       "      <td>-0.283751</td>\n",
       "      <td>0.395451</td>\n",
       "      <td>0.233139</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157871</th>\n",
       "      <td>110552.0</td>\n",
       "      <td>-2.450367</td>\n",
       "      <td>2.107729</td>\n",
       "      <td>-5.140663</td>\n",
       "      <td>1.411304</td>\n",
       "      <td>-1.690780</td>\n",
       "      <td>-0.736427</td>\n",
       "      <td>-3.657946</td>\n",
       "      <td>1.944906</td>\n",
       "      <td>-0.788388</td>\n",
       "      <td>-5.624677</td>\n",
       "      <td>3.519642</td>\n",
       "      <td>-7.221590</td>\n",
       "      <td>1.201728</td>\n",
       "      <td>-3.811428</td>\n",
       "      <td>-1.701428</td>\n",
       "      <td>-3.571408</td>\n",
       "      <td>-7.311407</td>\n",
       "      <td>-1.754355</td>\n",
       "      <td>0.795449</td>\n",
       "      <td>-0.130438</td>\n",
       "      <td>0.800538</td>\n",
       "      <td>0.364617</td>\n",
       "      <td>0.233608</td>\n",
       "      <td>-0.282078</td>\n",
       "      <td>-0.320311</td>\n",
       "      <td>0.492920</td>\n",
       "      <td>0.359976</td>\n",
       "      <td>-0.115471</td>\n",
       "      <td>80.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39183</th>\n",
       "      <td>39729.0</td>\n",
       "      <td>-0.964567</td>\n",
       "      <td>-1.643541</td>\n",
       "      <td>-0.187727</td>\n",
       "      <td>1.158253</td>\n",
       "      <td>-2.458336</td>\n",
       "      <td>0.852222</td>\n",
       "      <td>2.785163</td>\n",
       "      <td>-0.303609</td>\n",
       "      <td>0.940006</td>\n",
       "      <td>-1.965309</td>\n",
       "      <td>0.159744</td>\n",
       "      <td>-0.490697</td>\n",
       "      <td>-1.181977</td>\n",
       "      <td>-1.958876</td>\n",
       "      <td>1.152743</td>\n",
       "      <td>-1.341269</td>\n",
       "      <td>2.498325</td>\n",
       "      <td>0.777831</td>\n",
       "      <td>1.406045</td>\n",
       "      <td>1.784449</td>\n",
       "      <td>0.447180</td>\n",
       "      <td>0.536204</td>\n",
       "      <td>1.634061</td>\n",
       "      <td>0.203839</td>\n",
       "      <td>0.218749</td>\n",
       "      <td>-0.221886</td>\n",
       "      <td>-0.308555</td>\n",
       "      <td>-0.164500</td>\n",
       "      <td>776.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124036</th>\n",
       "      <td>77154.0</td>\n",
       "      <td>-0.715414</td>\n",
       "      <td>0.608590</td>\n",
       "      <td>1.155501</td>\n",
       "      <td>-0.267565</td>\n",
       "      <td>-0.563748</td>\n",
       "      <td>-0.618898</td>\n",
       "      <td>0.698308</td>\n",
       "      <td>0.069837</td>\n",
       "      <td>-0.133341</td>\n",
       "      <td>-1.025335</td>\n",
       "      <td>1.500629</td>\n",
       "      <td>-0.417898</td>\n",
       "      <td>-1.590295</td>\n",
       "      <td>-1.074999</td>\n",
       "      <td>0.288234</td>\n",
       "      <td>1.377769</td>\n",
       "      <td>0.223887</td>\n",
       "      <td>1.311073</td>\n",
       "      <td>-0.896072</td>\n",
       "      <td>-0.186978</td>\n",
       "      <td>0.130749</td>\n",
       "      <td>0.239389</td>\n",
       "      <td>-0.090227</td>\n",
       "      <td>0.411572</td>\n",
       "      <td>-0.216126</td>\n",
       "      <td>0.353896</td>\n",
       "      <td>-0.062361</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>129.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69644</th>\n",
       "      <td>53515.0</td>\n",
       "      <td>-0.958065</td>\n",
       "      <td>0.816749</td>\n",
       "      <td>1.764786</td>\n",
       "      <td>0.983298</td>\n",
       "      <td>-0.751082</td>\n",
       "      <td>0.394793</td>\n",
       "      <td>-0.565611</td>\n",
       "      <td>0.804178</td>\n",
       "      <td>0.108685</td>\n",
       "      <td>-0.185877</td>\n",
       "      <td>0.358119</td>\n",
       "      <td>0.703584</td>\n",
       "      <td>-0.305869</td>\n",
       "      <td>0.054320</td>\n",
       "      <td>-0.286488</td>\n",
       "      <td>0.167986</td>\n",
       "      <td>-0.179169</td>\n",
       "      <td>0.846151</td>\n",
       "      <td>0.960418</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.027101</td>\n",
       "      <td>0.182440</td>\n",
       "      <td>-0.044085</td>\n",
       "      <td>-0.014467</td>\n",
       "      <td>0.132699</td>\n",
       "      <td>-0.309969</td>\n",
       "      <td>0.079119</td>\n",
       "      <td>-0.013875</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "53794    46149.0 -1.346509  2.132431 -1.854355  2.116998 -1.070378 -1.092671   \n",
       "157871  110552.0 -2.450367  2.107729 -5.140663  1.411304 -1.690780 -0.736427   \n",
       "39183    39729.0 -0.964567 -1.643541 -0.187727  1.158253 -2.458336  0.852222   \n",
       "124036   77154.0 -0.715414  0.608590  1.155501 -0.267565 -0.563748 -0.618898   \n",
       "69644    53515.0 -0.958065  0.816749  1.764786  0.983298 -0.751082  0.394793   \n",
       "\n",
       "              V7        V8        V9       V10       V11       V12       V13  \\\n",
       "53794  -2.230986  1.036425 -1.895516 -3.364011  2.887048 -3.784460 -1.288904   \n",
       "157871 -3.657946  1.944906 -0.788388 -5.624677  3.519642 -7.221590  1.201728   \n",
       "39183   2.785163 -0.303609  0.940006 -1.965309  0.159744 -0.490697 -1.181977   \n",
       "124036  0.698308  0.069837 -0.133341 -1.025335  1.500629 -0.417898 -1.590295   \n",
       "69644  -0.565611  0.804178  0.108685 -0.185877  0.358119  0.703584 -0.305869   \n",
       "\n",
       "             V14       V15       V16       V17       V18       V19       V20  \\\n",
       "53794  -3.985626  0.531838 -2.603703 -5.157596 -0.696010  1.285961  0.221919   \n",
       "157871 -3.811428 -1.701428 -3.571408 -7.311407 -1.754355  0.795449 -0.130438   \n",
       "39183  -1.958876  1.152743 -1.341269  2.498325  0.777831  1.406045  1.784449   \n",
       "124036 -1.074999  0.288234  1.377769  0.223887  1.311073 -0.896072 -0.186978   \n",
       "69644   0.054320 -0.286488  0.167986 -0.179169  0.846151  0.960418  0.005882   \n",
       "\n",
       "             V21       V22       V23       V24       V25       V26       V27  \\\n",
       "53794   0.609508  0.202874 -0.060791 -0.186733 -0.017401 -0.283751  0.395451   \n",
       "157871  0.800538  0.364617  0.233608 -0.282078 -0.320311  0.492920  0.359976   \n",
       "39183   0.447180  0.536204  1.634061  0.203839  0.218749 -0.221886 -0.308555   \n",
       "124036  0.130749  0.239389 -0.090227  0.411572 -0.216126  0.353896 -0.062361   \n",
       "69644   0.027101  0.182440 -0.044085 -0.014467  0.132699 -0.309969  0.079119   \n",
       "\n",
       "             V28  Amount  Class  \n",
       "53794   0.233139    1.00      1  \n",
       "157871 -0.115471   80.22      1  \n",
       "39183  -0.164500  776.83      1  \n",
       "124036  0.008433  129.00      1  \n",
       "69644  -0.013875   12.99      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = normal_df.sample(frac=1, random_state = 4)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(new_df.Class);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>scaled_Time</th>\n",
       "      <th>scaled_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53794</th>\n",
       "      <td>-1.346509</td>\n",
       "      <td>2.132431</td>\n",
       "      <td>-1.854355</td>\n",
       "      <td>2.116998</td>\n",
       "      <td>-1.070378</td>\n",
       "      <td>-1.092671</td>\n",
       "      <td>-2.230986</td>\n",
       "      <td>1.036425</td>\n",
       "      <td>-1.895516</td>\n",
       "      <td>-3.364011</td>\n",
       "      <td>2.887048</td>\n",
       "      <td>-3.784460</td>\n",
       "      <td>-1.288904</td>\n",
       "      <td>-3.985626</td>\n",
       "      <td>0.531838</td>\n",
       "      <td>-2.603703</td>\n",
       "      <td>-5.157596</td>\n",
       "      <td>-0.696010</td>\n",
       "      <td>1.285961</td>\n",
       "      <td>0.221919</td>\n",
       "      <td>0.609508</td>\n",
       "      <td>0.202874</td>\n",
       "      <td>-0.060791</td>\n",
       "      <td>-0.186733</td>\n",
       "      <td>-0.017401</td>\n",
       "      <td>-0.283751</td>\n",
       "      <td>0.395451</td>\n",
       "      <td>0.233139</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.875044</td>\n",
       "      <td>-0.453121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157871</th>\n",
       "      <td>-2.450367</td>\n",
       "      <td>2.107729</td>\n",
       "      <td>-5.140663</td>\n",
       "      <td>1.411304</td>\n",
       "      <td>-1.690780</td>\n",
       "      <td>-0.736427</td>\n",
       "      <td>-3.657946</td>\n",
       "      <td>1.944906</td>\n",
       "      <td>-0.788388</td>\n",
       "      <td>-5.624677</td>\n",
       "      <td>3.519642</td>\n",
       "      <td>-7.221590</td>\n",
       "      <td>1.201728</td>\n",
       "      <td>-3.811428</td>\n",
       "      <td>-1.701428</td>\n",
       "      <td>-3.571408</td>\n",
       "      <td>-7.311407</td>\n",
       "      <td>-1.754355</td>\n",
       "      <td>0.795449</td>\n",
       "      <td>-0.130438</td>\n",
       "      <td>0.800538</td>\n",
       "      <td>0.364617</td>\n",
       "      <td>0.233608</td>\n",
       "      <td>-0.282078</td>\n",
       "      <td>-0.320311</td>\n",
       "      <td>0.492920</td>\n",
       "      <td>0.359976</td>\n",
       "      <td>-0.115471</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456890</td>\n",
       "      <td>-0.136723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39183</th>\n",
       "      <td>-0.964567</td>\n",
       "      <td>-1.643541</td>\n",
       "      <td>-0.187727</td>\n",
       "      <td>1.158253</td>\n",
       "      <td>-2.458336</td>\n",
       "      <td>0.852222</td>\n",
       "      <td>2.785163</td>\n",
       "      <td>-0.303609</td>\n",
       "      <td>0.940006</td>\n",
       "      <td>-1.965309</td>\n",
       "      <td>0.159744</td>\n",
       "      <td>-0.490697</td>\n",
       "      <td>-1.181977</td>\n",
       "      <td>-1.958876</td>\n",
       "      <td>1.152743</td>\n",
       "      <td>-1.341269</td>\n",
       "      <td>2.498325</td>\n",
       "      <td>0.777831</td>\n",
       "      <td>1.406045</td>\n",
       "      <td>1.784449</td>\n",
       "      <td>0.447180</td>\n",
       "      <td>0.536204</td>\n",
       "      <td>1.634061</td>\n",
       "      <td>0.203839</td>\n",
       "      <td>0.218749</td>\n",
       "      <td>-0.221886</td>\n",
       "      <td>-0.308555</td>\n",
       "      <td>-0.164500</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.007817</td>\n",
       "      <td>2.645479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124036</th>\n",
       "      <td>-0.715414</td>\n",
       "      <td>0.608590</td>\n",
       "      <td>1.155501</td>\n",
       "      <td>-0.267565</td>\n",
       "      <td>-0.563748</td>\n",
       "      <td>-0.618898</td>\n",
       "      <td>0.698308</td>\n",
       "      <td>0.069837</td>\n",
       "      <td>-0.133341</td>\n",
       "      <td>-1.025335</td>\n",
       "      <td>1.500629</td>\n",
       "      <td>-0.417898</td>\n",
       "      <td>-1.590295</td>\n",
       "      <td>-1.074999</td>\n",
       "      <td>0.288234</td>\n",
       "      <td>1.377769</td>\n",
       "      <td>0.223887</td>\n",
       "      <td>1.311073</td>\n",
       "      <td>-0.896072</td>\n",
       "      <td>-0.186978</td>\n",
       "      <td>0.130749</td>\n",
       "      <td>0.239389</td>\n",
       "      <td>-0.090227</td>\n",
       "      <td>0.411572</td>\n",
       "      <td>-0.216126</td>\n",
       "      <td>0.353896</td>\n",
       "      <td>-0.062361</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.233822</td>\n",
       "      <td>0.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69644</th>\n",
       "      <td>-0.958065</td>\n",
       "      <td>0.816749</td>\n",
       "      <td>1.764786</td>\n",
       "      <td>0.983298</td>\n",
       "      <td>-0.751082</td>\n",
       "      <td>0.394793</td>\n",
       "      <td>-0.565611</td>\n",
       "      <td>0.804178</td>\n",
       "      <td>0.108685</td>\n",
       "      <td>-0.185877</td>\n",
       "      <td>0.358119</td>\n",
       "      <td>0.703584</td>\n",
       "      <td>-0.305869</td>\n",
       "      <td>0.054320</td>\n",
       "      <td>-0.286488</td>\n",
       "      <td>0.167986</td>\n",
       "      <td>-0.179169</td>\n",
       "      <td>0.846151</td>\n",
       "      <td>0.960418</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.027101</td>\n",
       "      <td>0.182440</td>\n",
       "      <td>-0.044085</td>\n",
       "      <td>-0.014467</td>\n",
       "      <td>0.132699</td>\n",
       "      <td>-0.309969</td>\n",
       "      <td>0.079119</td>\n",
       "      <td>-0.013875</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.722706</td>\n",
       "      <td>-0.405234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219892</th>\n",
       "      <td>0.120301</td>\n",
       "      <td>1.974141</td>\n",
       "      <td>-0.434087</td>\n",
       "      <td>5.390793</td>\n",
       "      <td>1.289684</td>\n",
       "      <td>0.280590</td>\n",
       "      <td>0.221963</td>\n",
       "      <td>0.067827</td>\n",
       "      <td>-1.387054</td>\n",
       "      <td>-0.045125</td>\n",
       "      <td>0.195839</td>\n",
       "      <td>-0.629086</td>\n",
       "      <td>0.681222</td>\n",
       "      <td>-4.715521</td>\n",
       "      <td>-0.287876</td>\n",
       "      <td>0.497434</td>\n",
       "      <td>3.871618</td>\n",
       "      <td>1.492394</td>\n",
       "      <td>0.506040</td>\n",
       "      <td>0.205691</td>\n",
       "      <td>-0.038690</td>\n",
       "      <td>0.204554</td>\n",
       "      <td>-0.167313</td>\n",
       "      <td>0.791547</td>\n",
       "      <td>-0.223675</td>\n",
       "      <td>0.473223</td>\n",
       "      <td>-0.160202</td>\n",
       "      <td>0.065039</td>\n",
       "      <td>1</td>\n",
       "      <td>1.105722</td>\n",
       "      <td>-0.454080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95534</th>\n",
       "      <td>1.193916</td>\n",
       "      <td>-0.571085</td>\n",
       "      <td>0.742522</td>\n",
       "      <td>-0.014588</td>\n",
       "      <td>-0.624561</td>\n",
       "      <td>0.832162</td>\n",
       "      <td>-0.833350</td>\n",
       "      <td>0.272897</td>\n",
       "      <td>1.169425</td>\n",
       "      <td>-0.371672</td>\n",
       "      <td>-0.245677</td>\n",
       "      <td>1.375941</td>\n",
       "      <td>0.870457</td>\n",
       "      <td>-0.819319</td>\n",
       "      <td>-1.550904</td>\n",
       "      <td>0.125853</td>\n",
       "      <td>-0.397246</td>\n",
       "      <td>0.272377</td>\n",
       "      <td>1.226022</td>\n",
       "      <td>0.062908</td>\n",
       "      <td>-0.049502</td>\n",
       "      <td>0.207265</td>\n",
       "      <td>-0.265272</td>\n",
       "      <td>-0.679294</td>\n",
       "      <td>0.511812</td>\n",
       "      <td>1.246604</td>\n",
       "      <td>-0.028671</td>\n",
       "      <td>-0.006112</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.477778</td>\n",
       "      <td>-0.329669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221955</th>\n",
       "      <td>1.887225</td>\n",
       "      <td>-1.449215</td>\n",
       "      <td>-0.139307</td>\n",
       "      <td>-0.861318</td>\n",
       "      <td>-1.412395</td>\n",
       "      <td>-0.041161</td>\n",
       "      <td>-1.255357</td>\n",
       "      <td>0.072770</td>\n",
       "      <td>0.033011</td>\n",
       "      <td>0.785529</td>\n",
       "      <td>0.747559</td>\n",
       "      <td>0.611636</td>\n",
       "      <td>1.148448</td>\n",
       "      <td>-0.663241</td>\n",
       "      <td>-0.313445</td>\n",
       "      <td>1.749028</td>\n",
       "      <td>-0.413296</td>\n",
       "      <td>-0.515891</td>\n",
       "      <td>0.735172</td>\n",
       "      <td>0.288107</td>\n",
       "      <td>0.338102</td>\n",
       "      <td>0.789464</td>\n",
       "      <td>0.111406</td>\n",
       "      <td>-0.297992</td>\n",
       "      <td>-0.454191</td>\n",
       "      <td>-0.271566</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>-0.026219</td>\n",
       "      <td>0</td>\n",
       "      <td>1.123011</td>\n",
       "      <td>0.049274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198029</th>\n",
       "      <td>-0.801287</td>\n",
       "      <td>-0.355584</td>\n",
       "      <td>0.997339</td>\n",
       "      <td>-3.332366</td>\n",
       "      <td>-0.064676</td>\n",
       "      <td>0.183281</td>\n",
       "      <td>-0.094492</td>\n",
       "      <td>0.063676</td>\n",
       "      <td>-2.261618</td>\n",
       "      <td>0.826249</td>\n",
       "      <td>-0.239217</td>\n",
       "      <td>-1.315742</td>\n",
       "      <td>-0.682582</td>\n",
       "      <td>-0.279033</td>\n",
       "      <td>-1.297041</td>\n",
       "      <td>-0.025150</td>\n",
       "      <td>-0.157791</td>\n",
       "      <td>0.775712</td>\n",
       "      <td>-0.105737</td>\n",
       "      <td>-0.466040</td>\n",
       "      <td>-0.169303</td>\n",
       "      <td>-0.246200</td>\n",
       "      <td>-0.353229</td>\n",
       "      <td>0.042940</td>\n",
       "      <td>0.753452</td>\n",
       "      <td>-0.152020</td>\n",
       "      <td>-0.243336</td>\n",
       "      <td>0.023658</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906499</td>\n",
       "      <td>-0.397206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21518</th>\n",
       "      <td>0.511325</td>\n",
       "      <td>-1.863509</td>\n",
       "      <td>0.066864</td>\n",
       "      <td>-0.297128</td>\n",
       "      <td>-1.516824</td>\n",
       "      <td>-0.862754</td>\n",
       "      <td>0.112802</td>\n",
       "      <td>-0.352179</td>\n",
       "      <td>-0.929126</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.174441</td>\n",
       "      <td>0.917412</td>\n",
       "      <td>-0.178133</td>\n",
       "      <td>0.801901</td>\n",
       "      <td>1.266731</td>\n",
       "      <td>0.194129</td>\n",
       "      <td>-1.565357</td>\n",
       "      <td>0.455877</td>\n",
       "      <td>1.054582</td>\n",
       "      <td>0.193080</td>\n",
       "      <td>-0.588281</td>\n",
       "      <td>-0.280909</td>\n",
       "      <td>0.413267</td>\n",
       "      <td>0.081751</td>\n",
       "      <td>-0.533282</td>\n",
       "      <td>-0.073240</td>\n",
       "      <td>0.104904</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.173495</td>\n",
       "      <td>1.430330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "53794  -1.346509  2.132431 -1.854355  2.116998 -1.070378 -1.092671 -2.230986   \n",
       "157871 -2.450367  2.107729 -5.140663  1.411304 -1.690780 -0.736427 -3.657946   \n",
       "39183  -0.964567 -1.643541 -0.187727  1.158253 -2.458336  0.852222  2.785163   \n",
       "124036 -0.715414  0.608590  1.155501 -0.267565 -0.563748 -0.618898  0.698308   \n",
       "69644  -0.958065  0.816749  1.764786  0.983298 -0.751082  0.394793 -0.565611   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "219892  0.120301  1.974141 -0.434087  5.390793  1.289684  0.280590  0.221963   \n",
       "95534   1.193916 -0.571085  0.742522 -0.014588 -0.624561  0.832162 -0.833350   \n",
       "221955  1.887225 -1.449215 -0.139307 -0.861318 -1.412395 -0.041161 -1.255357   \n",
       "198029 -0.801287 -0.355584  0.997339 -3.332366 -0.064676  0.183281 -0.094492   \n",
       "21518   0.511325 -1.863509  0.066864 -0.297128 -1.516824 -0.862754  0.112802   \n",
       "\n",
       "              V8        V9       V10       V11       V12       V13       V14  \\\n",
       "53794   1.036425 -1.895516 -3.364011  2.887048 -3.784460 -1.288904 -3.985626   \n",
       "157871  1.944906 -0.788388 -5.624677  3.519642 -7.221590  1.201728 -3.811428   \n",
       "39183  -0.303609  0.940006 -1.965309  0.159744 -0.490697 -1.181977 -1.958876   \n",
       "124036  0.069837 -0.133341 -1.025335  1.500629 -0.417898 -1.590295 -1.074999   \n",
       "69644   0.804178  0.108685 -0.185877  0.358119  0.703584 -0.305869  0.054320   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "219892  0.067827 -1.387054 -0.045125  0.195839 -0.629086  0.681222 -4.715521   \n",
       "95534   0.272897  1.169425 -0.371672 -0.245677  1.375941  0.870457 -0.819319   \n",
       "221955  0.072770  0.033011  0.785529  0.747559  0.611636  1.148448 -0.663241   \n",
       "198029  0.063676 -2.261618  0.826249 -0.239217 -1.315742 -0.682582 -0.279033   \n",
       "21518  -0.352179 -0.929126  0.375034 -0.061708 -0.174441  0.917412 -0.178133   \n",
       "\n",
       "             V15       V16       V17       V18       V19       V20       V21  \\\n",
       "53794   0.531838 -2.603703 -5.157596 -0.696010  1.285961  0.221919  0.609508   \n",
       "157871 -1.701428 -3.571408 -7.311407 -1.754355  0.795449 -0.130438  0.800538   \n",
       "39183   1.152743 -1.341269  2.498325  0.777831  1.406045  1.784449  0.447180   \n",
       "124036  0.288234  1.377769  0.223887  1.311073 -0.896072 -0.186978  0.130749   \n",
       "69644  -0.286488  0.167986 -0.179169  0.846151  0.960418  0.005882  0.027101   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "219892 -0.287876  0.497434  3.871618  1.492394  0.506040  0.205691 -0.038690   \n",
       "95534  -1.550904  0.125853 -0.397246  0.272377  1.226022  0.062908 -0.049502   \n",
       "221955 -0.313445  1.749028 -0.413296 -0.515891  0.735172  0.288107  0.338102   \n",
       "198029 -1.297041 -0.025150 -0.157791  0.775712 -0.105737 -0.466040 -0.169303   \n",
       "21518   0.801901  1.266731  0.194129 -1.565357  0.455877  1.054582  0.193080   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "53794   0.202874 -0.060791 -0.186733 -0.017401 -0.283751  0.395451  0.233139   \n",
       "157871  0.364617  0.233608 -0.282078 -0.320311  0.492920  0.359976 -0.115471   \n",
       "39183   0.536204  1.634061  0.203839  0.218749 -0.221886 -0.308555 -0.164500   \n",
       "124036  0.239389 -0.090227  0.411572 -0.216126  0.353896 -0.062361  0.008433   \n",
       "69644   0.182440 -0.044085 -0.014467  0.132699 -0.309969  0.079119 -0.013875   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "219892  0.204554 -0.167313  0.791547 -0.223675  0.473223 -0.160202  0.065039   \n",
       "95534   0.207265 -0.265272 -0.679294  0.511812  1.246604 -0.028671 -0.006112   \n",
       "221955  0.789464  0.111406 -0.297992 -0.454191 -0.271566  0.017408 -0.026219   \n",
       "198029 -0.246200 -0.353229  0.042940  0.753452 -0.152020 -0.243336  0.023658   \n",
       "21518  -0.588281 -0.280909  0.413267  0.081751 -0.533282 -0.073240  0.104904   \n",
       "\n",
       "        Class  scaled_Time  scaled_Amount  \n",
       "53794       1    -0.875044      -0.453121  \n",
       "157871      1     0.456890      -0.136723  \n",
       "39183       1    -1.007817       2.645479  \n",
       "124036      1    -0.233822       0.058100  \n",
       "69644       0    -0.722706      -0.405234  \n",
       "...       ...          ...            ...  \n",
       "219892      1     1.105722      -0.454080  \n",
       "95534       1    -0.477778      -0.329669  \n",
       "221955      0     1.123011       0.049274  \n",
       "198029      0     0.906499      -0.397206  \n",
       "21518       0    -1.173495       1.430330  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_Time = scaler.fit_transform(new_df[\"Time\"].values.reshape(-1,1))\n",
    "scaled_Amount = scaler.fit_transform(new_df[\"Amount\"].values.reshape(-1,1))\n",
    "\n",
    "new_df[\"scaled_Time\"] = scaled_Time\n",
    "new_df[\"scaled_Amount\"] = scaled_Amount\n",
    "\n",
    "new_df = new_df.drop(columns = {\"Time\", \"Amount\"})\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veride Time ve Amount sütunları hariç diğer sütunlar zaten ölçeklendirildiğinden dolayı sadece bu 2 sütuna ölçeklendirme yapıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop(columns = \"Class\")\n",
    "y = new_df.Class\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.902027027027027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Karar Ağacı Objesi\n",
    "dectree = DecisionTreeClassifier()\n",
    "\n",
    "#Modeli Eğitme\n",
    "dectree_model = dectree.fit(X_train,y_train)\n",
    "\n",
    "#Tahmin\n",
    "dectree_y_pred = dectree_model.predict(X_test)\n",
    "\n",
    "#Doğruluk\n",
    "dectree_acc = metrics.accuracy_score(y_test, dectree_y_pred)\n",
    "print(\"Accuracy:\",dectree_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9391891891891891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Lojistik Regresyon Objesi\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#Modeli Eğitme\n",
    "logreg_model = logreg.fit(X_train,y_train)\n",
    "\n",
    "#Tahmin\n",
    "logreg_y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "#Doğruluk\n",
    "logreg_acc = metrics.accuracy_score(y_test, logreg_y_pred)\n",
    "print(\"Accuracy:\",logreg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9391891891891891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#KNN Objesi\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Modeli Eğitme\n",
    "knn_model = knn.fit(X_train,y_train)\n",
    "\n",
    "#Tahmin\n",
    "knn_y_pred = knn_model.predict(X_test)\n",
    "\n",
    "#Doğruluk\n",
    "knn_acc = metrics.accuracy_score(y_test, knn_y_pred)\n",
    "print(\"Accuracy:\", knn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8986486486486487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Naive Bayes Objesi\n",
    "nb = GaussianNB()\n",
    "\n",
    "#Modeli Eğitme\n",
    "nb_model = nb.fit(X_train,y_train)\n",
    "\n",
    "#Tahmin\n",
    "nb_y_pred = nb_model.predict(X_test)\n",
    "\n",
    "#Doğruluk\n",
    "nb_acc = metrics.accuracy_score(y_test, nb_y_pred)\n",
    "print(\"Accuracy:\", nb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9256756756756757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#Karar Ağacı Objesi\n",
    "svc = SVC()\n",
    "\n",
    "#Modeli Eğitme\n",
    "svc_model = svc.fit(X_train,y_train)\n",
    "\n",
    "#Tahmin\n",
    "svc_y_pred = svc_model.predict(X_test)\n",
    "\n",
    "#Doğruluk\n",
    "svc_acc = metrics.accuracy_score(y_test, svc_y_pred)\n",
    "print(\"Accuracy:\", svc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9324324324324325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Karar Ağacı Objesi\n",
    "ranfor = RandomForestClassifier()\n",
    "\n",
    "#Modeli Eğitme\n",
    "ranfor_model = ranfor.fit(X_train,y_train)\n",
    "\n",
    "#Tahmin\n",
    "ranfor_y_pred = ranfor_model.predict(X_test)\n",
    "\n",
    "#Doğruluk\n",
    "ranfor_acc = metrics.accuracy_score(y_test, ranfor_y_pred)\n",
    "print(\"Accuracy:\", ranfor_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               7936      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 51,234\n",
      "Trainable params: 51,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "\n",
    "model = Models.Sequential()\n",
    "\n",
    "model.add(Layers.Dense(256, activation = 'relu', input_shape = (X_train.shape[1], )))\n",
    "model.add(Layers.Dense(128, activation = 'relu'))\n",
    "model.add(Layers.Dense(64, activation = 'relu'))\n",
    "model.add(Layers.Dense(32, activation = 'relu'))\n",
    "model.add(Layers.Dense(2, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = Optimizer.Adam(lr=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6336 - accuracy: 0.6642\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4239 - accuracy: 0.8241\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 0s 938us/step - loss: 0.3620 - accuracy: 0.9041\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.9302\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 0s 952us/step - loss: 0.2712 - accuracy: 0.9331\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 0s 986us/step - loss: 0.2375 - accuracy: 0.9346\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 0s 969us/step - loss: 0.2104 - accuracy: 0.9404\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 0s 993us/step - loss: 0.1893 - accuracy: 0.9419\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 0.1718 - accuracy: 0.9433\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9448\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 0s 952us/step - loss: 0.1449 - accuracy: 0.9506\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 0s 993us/step - loss: 0.1353 - accuracy: 0.9520\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 0s 908us/step - loss: 0.1257 - accuracy: 0.9535\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 0s 935us/step - loss: 0.1193 - accuracy: 0.9564\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 0s 924us/step - loss: 0.1128 - accuracy: 0.9578\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 0s 861us/step - loss: 0.1070 - accuracy: 0.9578\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 0s 861us/step - loss: 0.1014 - accuracy: 0.9593\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 0s 890us/step - loss: 0.0970 - accuracy: 0.9608\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 0s 863us/step - loss: 0.0927 - accuracy: 0.9622\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 0s 964us/step - loss: 0.0889 - accuracy: 0.9637\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 0s 831us/step - loss: 0.0851 - accuracy: 0.9666\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 0s 784us/step - loss: 0.0812 - accuracy: 0.9680\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 0s 861us/step - loss: 0.0780 - accuracy: 0.9680\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 0s 907us/step - loss: 0.0747 - accuracy: 0.9709\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 0s 874us/step - loss: 0.0721 - accuracy: 0.9695\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 0s 861us/step - loss: 0.0694 - accuracy: 0.9738\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 0s 897us/step - loss: 0.0662 - accuracy: 0.9797\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 0s 861us/step - loss: 0.0633 - accuracy: 0.9811\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 0s 867us/step - loss: 0.0605 - accuracy: 0.9811\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 0s 897us/step - loss: 0.0586 - accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "trained = model.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 698us/step - loss: 0.1821 - accuracy: 0.9392\n"
     ]
    }
   ],
   "source": [
    "nn_acc = model.evaluate(X_test, y_test, verbose=1)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
